# 🧭 ISUCON 学習ノート

## 🎯 全体ゴール
ISUCON出場・完走・スコアアップ  
→ ボトルネック特定から改善までを一人で完遂できるようになる。

---

## 📘 知識マップ進捗

| カテゴリ | 学習状況 | 学ぶ主題（ISUCONで求められる観点） | メモ |
|-----------|------------|------------------------------------|------|
| **OS / Linux** | ⚪ 未着手 | CPU・メモリ・I/O、プロセス・スレッド監視（top, dstat） | |
| **Webサーバ** | ⚪ 未着手 | Nginx設定、Keep-Alive、リバースプロキシ、静的キャッシュ | |
| **アプリケーション** | 🔵 習得中 | Express/Rust最適化、非同期処理、キャッシュ戦略 | キャッシュは重い処理（10ms以上）で効果発揮、アムダールの法則で効果判定 |
| **データベース** | 🔵 習得中 | MySQL INDEX、N+1対策、EXPLAINによる分析 | MySQL接続・クエリ実行、EXPLAINで実行計画確認、type=ALL（フルスキャン）とtype=ref（インデックス使用）の理解、インデックス作成と効果測定、複合インデックス・カバリングインデックスの比較、Using index/Using index condition/Using whereの違い、MySQLオプティマイザの意思決定構造（左端一致、統計情報、選択性、コストベース最適化）の理解、ORDER BY/LIMITのインデックス最適化、type=index（インデックスフルスキャン）とfilesortの関係、FORCE INDEXの活用 |
| **ベンチ / 計測** | 🔵 習得中 | autocannon・wrkなどでの負荷試験・再測定 | processingTimeMs追加、キャッシュあり/なし比較で効果可視化、インデックス効果測定の実践 |
| **観測 / 可視化** | 🔵 習得中 | p95/p99レイテンシ、slow query log、メトリクス分析 | 処理時間をレスポンスに含めて可視化、統計エンドポイント実装、EXPLAINで実行計画を可視化 |
| **環境構築** | 🟢 開始 | Docker/Composeで再現環境を作る | Docker ComposeでMySQL環境構築 |
| **チーム運用** | ⚪ 未着手 | コード・設定共有、再現性担保 | |
| **メンタルモデル** | 🟢 開始 | 計測→改善→再測定のループ思考 | ボトルネック特定→改善→計測のループ実践、効果の数値確認が重要 |

---

> 💡 **環境構築・躓きポイント**は別ファイルに移動しました  
> → [`troubleshooting-notes.md`](./troubleshooting-notes.md)

---

## 🚀 実践タスクログ

### Day 1（2025-11-02）
- **テーマ:** Express APIサーバー作成とベンチマーク実行
- **アクション:** ExpressでAPIサーバーを作成、autocannonでベンチマーク実行
- **結果:** 
- **気づき:** node.js上で簡単にAPIサーバーが作成できる。autocannonという負荷テストツールがある。k6などより、npm install数が多いらしい

### Day 2（2025-11-03）
- **テーマ:** キャッシュ戦略の効果検証と最適化
- **アクション:** 
  - メモリキャッシュの実装
  - 重い処理をシミュレートしてキャッシュ効果を可視化
  - キャッシュあり/なしでのパフォーマンス比較
- **結果:** 
  - キャッシュなし: 80 req/s, 122.81ms latency, 20ms processing
  - キャッシュあり: 3,119 req/s, 2.68ms latency, 0ms processing
  - **約39倍の性能向上**を達成
- **気づき:** キャッシュは重い処理がある時に効果を発揮する。処理が軽すぎると効果が見えない。

### Day 3（2025-11-03）
- **テーマ:** アプリのDB化とEXPLAINで実行計画を読む
- **アクション:** 
  - ExpressアプリをMySQL接続に変更
  - Docker ComposeでMySQL環境を構築
  - `/items-db`（キャッシュなし）と `/items-db-cache`（TTLキャッシュ）を実装
  - DBアクセスありでのベンチマーク実行
  - EXPLAINで実行計画を確認
- **結果:** 
  - DBキャッシュなし: 1,321 req/s, 7.06ms latency, 1ms processing
  - DBキャッシュあり: 2,777 req/s, 3.06ms latency, 0ms processing
  - **約2.1倍の性能向上**を達成（DBアクセスは約1msと軽いため効果は相対的に小さい）
  - EXPLAIN結果: `type=ALL`（フルスキャン）、`key=NULL`（インデックス未使用）、`rows=6`
- **気づき:** 
  - mysqlのインストールはdockerから実施するパターンと直接インストールする方法がある（今回はdockerを利用）
  - DBアクセスもキャッシュで高速化できるが、元の処理が軽い（1ms）ため効果は相対的に小さい
  - EXPLAINで実行計画を確認すると、`type=ALL`は全件読んでいることが分かる
  - インデックスがない場合、WHERE条件なしの全件取得ではフルスキャンになる

### Day 4（2025-11-09）
- **テーマ:** インデックス作成と効果測定
- **アクション:** 
  - itemsテーブルのcategoryカラムにインデックス（idx_items_category）を追加
  - アプリケーションからcategoryクエリパラメータでフィルタリングできるように実装
  - インデックス使用時（WHERE category = 'Books'）とフルスキャン時（WHEREなし）のベンチマークを実行
  - EXPLAINで実行計画を確認してインデックス使用を検証
- **結果:** 
  - インデックスは正しく使用されている（EXPLAIN結果: `type=ref`, `key=idx_items_category`, `rows=25`）
  - しかし、パフォーマンス差がほとんどない（全件取得: 1309.70 req/s、category指定: 1056-1528 req/s）
  - 処理時間は両方とも1ms程度
- **気づき:** 
  - データ量が少なすぎる（100件）ため、フルスキャンでも一瞬で完了し、インデックス使用時も25行を読むだけなので差が小さい
  - 処理時間が1ms程度で、ネットワークやアプリのオーバーヘッドが支配的になる
  - インデックスの効果を測定するには、データ量を増やす必要がある（数千〜数万件以上）
  - EXPLAINで実行計画を確認することで、インデックスが使われているか確認できる（`type=ref`でインデックス使用、`type=ALL`でフルスキャン）

### Day 5（2025-11-09）
- **テーマ:** EXPLAINの詳細分析とインデックス最適化の理解
- **アクション:** MySQLの実行計画（EXPLAIN）の詳細分析を進め、複合インデックスとカバリングインデックスの挙動を比較した。Using where / Using index condition / Using index の違いを実例で観測し、インデックス利用の判断基準を理解した。
- **結果:** 
- **気づき:** Using index が出る＝テーブルアクセスなし（完全なカバリングINDEX）。Using index condition はテーブルアクセスを減らす中間状態（Index Condition Pushdown）。Using where はWHERE句評価をテーブル上で行う状態で、全件走査か部分最適化。選択性の低いインデックスでは逆に遅くなる場合もあり、オプティマイザがコストベースで最適化を選択する。MySQLオプティマイザの意思決定構造（左端一致、統計情報、選択性、ソート最適化など）を体系的に理解した。

### Day 6（2025-11-17）
- **テーマ:** ORDER BY / LIMIT のインデックス最適化
- **アクション:** 
  - `EXPLAIN SELECT * FROM items ORDER BY price DESC LIMIT 10` でベースライン取得
  - `idx_items_price`（price用インデックス）を作成
  - `FORCE INDEX` を使って、ORDER BY / LIMIT がインデックスだけで処理される挙動を確認
  - category 条件を加えた場合の Using where の意味を分析
- **結果:** 
  - price インデックスを貼ってもテーブルが小さすぎるため、MySQL はフルスキャン＋filesort を選択
  - `FORCE INDEX` を使うと、`type=index` でソートなしに LIMIT が効くことを確認
  - WHERE 条件（category）は price インデックスでは絞れないため Using where が出ることを確認
- **気づき:** 
  - インデックスは「ORDER BY / LIMIT」には効くが、WHERE 条件に使えないと結局 Using where が発生する
  - 小さなテーブルでは、MySQL が「インデックスよりフルスキャンの方が安い」と判断するケースがある
  - `type=index` は「インデックスフルスキャン」であり、LIMIT が効く場合は実質かなり高速に動く
  - 複合インデックス `(category, price)` を作れば WHERE も ORDER BY も LIMIT も "索引だけで完結" する可能性が高い

---

## 💡 学びのメモ

### キャッシュ最適化の原則：アムダールの法則

#### 問題：なぜ最初のコードではキャッシュ効果が感じられなかったか？

**以前のコード（軽量処理）**
- 処理内容: 単純な配列生成のみ `[{ id: 1, name: "Apple" }, ...]`
- 処理時間: 数マイクロ秒（ほぼ0ms）
- ベンチマーク結果: 4,402 req/s, 1.60ms latency
- **キャッシュ効果: ほとんど見られない**

**改善後のコード（重い処理あり）**
- 処理内容: CPU集約処理（10-20ms）+ I/O遅延（5-15ms） + 大きなデータセット（100アイテム）
- 処理時間: 合計15-35ms
- ベンチマーク結果:
  - キャッシュなし: 80 req/s, 122.81ms latency, 20ms processing
  - キャッシュあり: 3,119 req/s, 2.68ms latency, 0ms processing
- **キャッシュ効果: 約39倍の性能向上**

#### 理由の分析

1. **ボトルネックの位置が違った**
   - 以前: ボトルネックが**ネットワーク/Expressフレームワークのオーバーヘッド**（約1.6ms）
   - 改善後: ボトルネックが**アプリケーションの処理時間**（約20ms）
   - → キャッシュは処理時間を削減するが、フレームワークオーバーヘッドは削減できない

2. **アムダールの法則**
   ```
   全体の性能向上 = 1 / ((1 - P) + P/S)
   P = 最適化する部分の割合
   S = その部分の速度向上率
   ```
   - 以前: P ≈ 0.1%（処理時間が全体の0.1%程度）
   - 改善後: P ≈ 95%（処理時間が全体の95%）
   - → **最適化する部分の割合が大きいほど、効果が目に見える**

3. **コストバランス**
   - キャッシュチェックのコスト: 約0.01ms（if文 + メモリアクセス）
   - 以前の処理コスト: 約0.001ms（配列生成）
   - 改善後の処理コスト: 約20ms（重い処理）
   - → **処理コストが高いほど、キャッシュの相対的な効果が大きい**

#### 実践的な教訓

✅ **キャッシュが効果的な場面**
- DBクエリ、外部API呼び出し、重い計算処理がある時
- 処理時間が10ms以上かかる処理
- 同じデータが頻繁にアクセスされる

❌ **キャッシュの効果が薄い場面**
- 処理が非常に軽量（1ms未満）な時
- フレームワーク/ネットワークオーバーヘッドが支配的な時
- データが毎回異なる（キャッシュヒット率が低い）

#### ISUCONでの応用

1. **ボトルネックの特定が重要**
   - プロファイリングで時間がかかっている部分を特定
   - その部分が最適化対象になる

2. **キャッシュ戦略の選択**
   - 重い処理（DB、外部API）→ キャッシュが有効
   - 軽い処理 → キャッシュオーバーヘッドが目立つ可能性

3. **計測の重要性**
   - 感覚ではなく数値で効果を確認
   - `processingTimeMs`などの指標を追加して可視化 

### 初回リクエストのパフォーマンス問題とウォームアップ戦略

#### なぜ初回リクエストは遅くなりがちか？

**コールドスタート問題の原因**

1. **JITコンパイラの最適化（V8エンジン）**
   - 初回実行時、コードが解釈実行される（遅い）
   - 頻繁に実行されるコード（hot path）が検出されるまで時間がかかる
   - 最適化コンパイルが完了するまで、処理速度が低下
   - **影響**: 初回リクエストで数ms〜数十msの遅延が発生

2. **依存関係のロードと初期化**
   - モジュールのインポート、クラスの初期化
   - データベース接続プールの確立
   - 外部ライブラリの初期化処理
   - **影響**: 初回のみ数十ms〜数百msの遅延

3. **メモリの初期化とアロケーション**
   - ヒープメモリの初期確保
   - ガベージコレクタの調整（世代管理の確立）
   - キャッシュバッファの初期化
   - **影響**: メモリアクセスパターンの最適化が完了するまでの遅延

4. **キャッシュが空の状態**
   - メモリキャッシュが空で、重い処理を実行する必要がある
   - データベースクエリ結果のキャッシュが無い
   - 静的リソースのキャッシュが無い
   - **影響**: 初回のみ重い処理（DB、外部API）を実行するため遅い

5. **ネットワーク接続の確立**
   - TCP接続の確立（3-way handshake）
   - TLSハンドシェイク（HTTPSの場合）
   - Keep-Alive接続が確立されていない
   - **影響**: 初回リクエストで10-100ms程度の追加遅延

#### 実測例（現在のコード）

- **初回リクエスト**: `source: "fresh"`, `processingTimeMs: 20ms`（重い処理実行）
- **2回目以降**: `source: "cache"`, `processingTimeMs: 0ms`（キャッシュヒット）

**ベンチマークでの影響**
- 初回リクエストが計測に含まれると、平均レイテンシが押し上げられる
- 特に短い計測期間では、初回の遅延が全体に影響しやすい

#### ウォームアップ（キャッシュ予熱）戦略

**1. サーバー起動時の自動ウォームアップ**

```javascript
// サーバー起動時にキャッシュを事前ロード
app.listen(port, async () => {
  console.log(`Server running at http://localhost:${port}`);
  // 起動時にキャッシュをウォームアップ
  await warmupCache();
  console.log('Cache warmed up');
});
```

**メリット**:
- ベンチマーク開始時点でキャッシュが既に準備済み
- 初回リクエストが最速で処理される
- JITコンパイラの最適化も同時に促進

**デメリット**:
- サーバー起動時間が少し増える
- 起動時にリソースを使用

**2. ヘルスチェック経由でのウォームアップ**

ヘルスチェックエンドポイントから自動的にウォームアップリクエストを送信：

```javascript
app.get('/health', async (req, res) => {
  // ヘルスチェックのついでにキャッシュをウォームアップ
  if (!itemsCache) {
    await generateItems(); // バックグラウンドで実行
  }
  res.json({ status: 'ok' });
});
```

**3. バックグラウンドタスクでの継続的なプリロード**

定期的にアクセス頻度の高いデータをプリロード：

```javascript
// 定期的にキャッシュを更新
setInterval(async () => {
  if (itemsCache) {
    // キャッシュをバックグラウンドで更新
    const items = await generateItems();
    itemsCache = items;
  }
}, 60000); // 60秒ごと
```

**4. ベンチマーク実行前のウォームアップ**

ベンチマークスクリプト側で、本計測前にウォームアップリクエストを送信（既に実装済み）：

```javascript
// bench-logs.mjs のウォームアップ部分
await run({
  url,
  connections,
  duration: Math.min(3, Math.max(1, Math.floor(duration / 3))),
});
```

**5. 複数回のウォームアップリクエスト**

初回リクエストだけでなく、複数回リクエストしてJIT最適化も促進：

```javascript
async function warmupCache() {
  // 複数回リクエストしてJIT最適化も促進
  for (let i = 0; i < 5; i++) {
    await fetch('http://localhost:3000/items');
  }
}
```

#### ISUCONでの実践ポイント

1. **サーバー再起動前後の差を理解**
   - 再起動直後はコールドスタート状態
   - ベンチマークは通常、サーバー起動後に実行される
   - → ウォームアップが重要

2. **計測の公平性**
   - 初回リクエストを除外するか、十分なウォームアップを実施
   - ベンチマークツールのウォームアップ機能を活用

3. **本番環境での考慮**
   - デプロイ直後はパフォーマンスが低下する可能性
   - ヘルスチェックでウォームアップを兼ねる設計

4. **キャッシュの戦略的配置**
   - サーバー起動時に頻繁にアクセスされるデータを事前ロード
   - 起動時間とパフォーマンスのトレードオフを検討

### MySQL実行計画の理解：EXPLAIN

#### なぜEXPLAINを確認するのか？

MySQLはクエリを実行する前に「実行計画」を立てます。この計画を確認することで：
- どのようにデータを取得するかが分かる
- インデックスが使われているかが分かる
- パフォーマンスのボトルネックが分かる

#### 実行計画の読み方：重要なフィールド

**実測例（`SELECT id, name, description, price, category FROM items`）**

```
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: items
   partitions: NULL
         type: ALL          ← 重要：アクセスタイプ
possible_keys: NULL        ← 重要：使用可能なインデックス
          key: NULL        ← 重要：実際に使用されるインデックス
      key_len: NULL
          ref: NULL
         rows: 6           ← 重要：スキャンする行数の見積もり
     filtered: 100.00
        Extra: NULL
```

#### `type = ALL` の意味

**フルテーブルスキャン（Full Table Scan）**
- テーブル全体を先頭から最後まで読み込む
- **最も遅いアクセス方法**
- データが増えるほど時間がかかる（O(n)）

**なぜ `ALL` になるのか？**
1. **インデックスがない**: `possible_keys = NULL`, `key = NULL`
2. **WHERE条件がない**: 全件取得する必要がある
3. **全件読む必要がある**: 100行なら100行すべてを読む

#### 自分の言葉で説明できるように

**説明例：**
> 現在のクエリは `type=ALL` でフルテーブルスキャンを実行しています。`key=NULL` からインデックスが使われておらず、`rows=6` は約6行をスキャンする見積もりです。これが遅い原因の一つです。データが増えると、読み込む行数も増えるため、処理時間が長くなります。

#### 実践的な理解

**Q: なぜ遅いのか？**
- フルスキャンで全件読んでいる
- インデックスがないため、効率的な検索ができない
- データが増えるほど遅くなる

**Q: どうすれば改善できるか？**（今は理解のみ、実装は次のステップ）
- WHERE条件でフィルタリングする場合、そのカラムにインデックスを追加
- ただし、全件取得（WHERE条件なし）ではインデックスは効果が薄い

#### ISUCONでの実践ポイント

1. **実行計画を確認する習慣**
   - 新しいクエリを書いたら必ずEXPLAINで確認
   - `type=ALL` は要注意

2. **インデックスの効果を理解**
   - インデックスは「WHERE条件で絞り込む時」に効果を発揮
   - 全件取得では効果が薄い

3. **データ量との関係**
   - データが少ない（100行程度）なら `type=ALL` でも問題ない
   - データが増える（10,000行、100,000行）とフルスキャンは致命的

### 🧩 インデックス利用の3段階

| 状態 | Extra | 意味 | テーブルアクセス |
|------|-------|------|------------------|
| Using where | WHERE句評価をテーブル上で実施 | 全件 or 候補行を都度取得 | 多い（I/O大） |
| Using index condition | Index Condition Pushdown（ICP）で一部を索引上で評価 | 候補行を減らしてからテーブル読み | 中程度（I/O削減） |
| Using index | カバリングINDEX成立。SELECTに必要な列がすべて索引内 | テーブルを読まない | なし（最速） |

→ 目的は"Using where"を減らし、"Using index"に寄せること。

### ⚙️ カバリングインデックスの理解

SELECTで使うカラムすべてがインデックス内に含まれているとき、MySQLはテーブルを読まずに結果を返す。

- 暗黙的にPRIMARY KEYが含まれるため、`(category, price)` + `id`をSELECTしても成立
- `Using index` が出たらカバリング成功
- `SELECT *` にすると未索引カラムを読み込む必要があり、`Using index condition` に戻る

→ "どのカラムがINDEXに含まれているか"を意識してSELECT句を書く。

### 🧠 Index Condition Pushdown（ICP）の意義

- テーブルアクセスが完全に不要になるわけではない
- ただし「インデックス上で条件を評価」して不要な行を除外できるため、I/Oが減る
- 大規模テーブルで特に効果的

→ 「読む行数を減らす」こと自体が最適化。

### 🧮 オプティマイザの判断基準

MySQLはクエリ実行前にコストを見積もり、最安ルートを選択する（コストベース最適化）。

**主な判断軸：**

1. **選択性（絞り込みの強さ）**
   - indexでヒットする行数が少ないほど有利

2. **テーブルサイズ**
   - 小さいテーブルはフルスキャンが速い

3. **左端一致**
   - `(a,b)` インデックスなら、aが条件に含まれないと無効

4. **統計情報の鮮度**
   - `ANALYZE TABLE` で最新化が必要

5. **ORDER BY / LIMITとの整合**
   - 並び順や制限がindex順と一致すれば高速化可能（Day6で扱う）

→ MySQLは常にindexを使うとは限らない。コスト次第でフルスキャンを選ぶこともある。

### 🧠 実践で意識すべき判断軸（ISUCON的まとめ）

- **選択性 × I/O** で「どちらが速いか」を考える
- index利用による「ランダムI/O」が、フルスキャンの「連続I/O」を上回る場合もある
- オプティマイザの判断を鵜呑みにせず、EXPLAIN で根拠を観測する
- **絶対指標は「I/Oをどれだけ減らせたか」**

### ORDER BY / LIMIT のインデックス最適化

#### なぜORDER BY / LIMITにインデックスが効くのか？

**ORDER BY / LIMIT の高速化には「インデックス順のまま範囲を読む」ことが重要。**

- インデックスは既にソート済みの状態で保持されている
- `ORDER BY price DESC LIMIT 10` の場合、priceインデックスを逆順に読んで最初の10件だけ取得すればよい
- テーブル全体をソートする必要がない（`filesort`が不要）

#### 実践例：priceインデックスの効果

**ベースライン（インデックスなし）**
```sql
EXPLAIN SELECT * FROM items ORDER BY price DESC LIMIT 10;
```
- `type=ALL`（フルスキャン）
- `Extra=Using filesort`（ソート処理が必要）

**priceインデックス作成後**
```sql
CREATE INDEX idx_items_price ON items(price);
EXPLAIN SELECT * FROM items ORDER BY price DESC LIMIT 10;
```
- テーブルが小さい場合、MySQLは「フルスキャン＋filesort」の方が安いと判断
- `type=ALL`、`Extra=Using filesort` のまま（インデックスを使わない）

**FORCE INDEXで強制使用**
```sql
EXPLAIN SELECT * FROM items FORCE INDEX(idx_items_price) ORDER BY price DESC LIMIT 10;
```
- `type=index`（インデックスフルスキャン）
- `Extra=`（filesortなし）
- LIMITが効くため、実質的に高速

#### type=index の意味

- **インデックスフルスキャン**：インデックス全体を読む
- 一見すると遅そうだが、LIMITが効く場合は実質かなり高速
- インデックスはソート済みなので、先頭から必要な分だけ読めばよい

#### WHERE条件との組み合わせ

**問題：WHERE条件がインデックスに含まれていない場合**

```sql
SELECT * FROM items WHERE category='Books' ORDER BY price DESC LIMIT 10;
```

- priceインデックスだけではcategoryで絞れない
- `Using where`が発生：行ごとにcategory条件を評価する必要がある
- テーブルアクセスが必要になり、I/Oが増える

**解決策：複合インデックス**

```sql
CREATE INDEX idx_items_category_price ON items(category, price);
```

- WHERE条件（category）もORDER BY（price）も同じインデックスで処理可能
- `Using where`が消え、インデックスだけで完結する可能性が高い
- LIMITも効くため、非常に高速

#### オプティマイザの判断：なぜインデックスを使わないことがあるのか？

**小さなテーブルでの判断**

- テーブルが小さい（100行程度）場合、フルスキャン＋filesortの方が速いと判断される
- インデックスを読むコスト（ランダムI/O）が、フルスキャン（連続I/O）より高いと見積もられる
- オプティマイザはコストベースで最適化を選択する

**FORCE INDEXの活用**

- オプティマイザの判断が間違っている可能性がある場合に使用
- ただし、データ量が増えるとオプティマイザの判断が変わる可能性がある
- 本番環境では慎重に使用する

#### ISUCONでの実践ポイント

1. **ORDER BY / LIMIT クエリの最適化**
   - ソート対象のカラムにインデックスを作成
   - `type=index` で `filesort` が消えることを確認

2. **WHERE条件との組み合わせ**
   - WHERE条件とORDER BYの両方に対応する複合インデックスを検討
   - 左端一致を意識：`(category, price)` なら `WHERE category=? ORDER BY price` に有効

3. **LIMITの効果**
   - LIMITがある場合、インデックスフルスキャンでも実質高速
   - 必要な行数だけ読めばよいため

4. **オプティマイザとの付き合い方**
   - 小さなテーブルではインデックスを使わない判断も正しい場合がある
   - データ量が増えると判断が変わる可能性を理解する
   - EXPLAINで実行計画を常に確認する